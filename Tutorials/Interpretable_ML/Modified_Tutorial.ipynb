{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretable Machine Leaning with Python\n",
    "Adapted from [this tutorial](http://savvastjortjoglou.com/intrepretable-machine-learning-nfl-combine.html#PDP-and-ICE-plots) by Savvas Tjortjoglou <br>\n",
    "\n",
    "In this tutorial, you will:\n",
    "1. Train a Random Forest Regression model on data about football players\n",
    "2. Learn about Mean Decrease Impurity, Mean Decrease Accuracy  importance\n",
    "3. Learn how to evaluate and interpret feature contributions globally, and for single instances (decision paths), and various methods to visualize contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train a Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: <br>\n",
    "A. Create a conda environment with the packages we need (for whole tutorial) <br>\n",
    "B. Import packages (for whole tutorial)<br>\n",
    "C. Load in and subset the data we want to use in our model <br>\n",
    "D. Split training and testing data <br>\n",
    "E. Build the model <br>\n",
    "F. Tune model parameters and train <br>\n",
    "G. Apply model to test data and evaluate <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create conda Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Install in conda environment\n",
    "# conda install -c conda-forge -c ets skll\n",
    "# conda install -c conda-forge scikit-optimize\n",
    "# conda install -c conda-forge tqdm \n",
    "# conda install -c conda-forge eli5\n",
    "# conda install -c conda-forge graphviz \n",
    "# conda install -c conda-forge pydotplus\n",
    "# pip install treeinterpreter\n",
    "# pip install pycebox\n",
    "# conda install -c conda-forge pdpbox \n",
    "# conda install -c conda-forge xgboost <-- failed for Shinhan, worked for Serena \n",
    "# pip install xgboost <-- failed for Serena, worked for Shinhan\n",
    "# conda install -c conda-forge lime \n",
    "# conda install -c conda-forge shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer # this package is called scikit-learn\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV # this package is called scikit-optimize\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the aesthetic for the plots in this notebook\n",
    "sns.set(style=\"white\", palette=\"colorblind\", font_scale=1.2, \n",
    "        rc={\"figure.figsize\":(8,6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Load in and subset data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we're trying to predict the 'Approximate Value' (AV) of football players: an explanation can be found [here](https://www.pro-football-reference.com/about/glossary.htm). We are doing this using a dataset where instances are individual players, and there are various performance metrics for each player, which we will later use as features in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Forty</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>BenchReps</th>\n",
       "      <th>BroadJump</th>\n",
       "      <th>Cone</th>\n",
       "      <th>Shuttle</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pfr_ID</th>\n",
       "      <th>AV</th>\n",
       "      <th>Team</th>\n",
       "      <th>Round</th>\n",
       "      <th>Pick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Abraham</td>\n",
       "      <td>OLB</td>\n",
       "      <td>76</td>\n",
       "      <td>252</td>\n",
       "      <td>4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>AbraJo00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>New York Jets</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shaun Alexander</td>\n",
       "      <td>RB</td>\n",
       "      <td>72</td>\n",
       "      <td>218</td>\n",
       "      <td>4.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>AlexSh00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darnell Alford</td>\n",
       "      <td>OT</td>\n",
       "      <td>76</td>\n",
       "      <td>334</td>\n",
       "      <td>5.56</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.48</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2000</td>\n",
       "      <td>AlfoDa20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kyle Allamon</td>\n",
       "      <td>TE</td>\n",
       "      <td>74</td>\n",
       "      <td>253</td>\n",
       "      <td>4.97</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.29</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashard Anderson</td>\n",
       "      <td>CB</td>\n",
       "      <td>74</td>\n",
       "      <td>206</td>\n",
       "      <td>4.55</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2000</td>\n",
       "      <td>AndeRa21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Pos  Ht   Wt  Forty  Vertical  BenchReps  BroadJump  \\\n",
       "0      John Abraham  OLB  76  252   4.55       NaN        NaN        NaN   \n",
       "1   Shaun Alexander   RB  72  218   4.58       NaN        NaN        NaN   \n",
       "2    Darnell Alford   OT  76  334   5.56      25.0       23.0       94.0   \n",
       "3      Kyle Allamon   TE  74  253   4.97      29.0        NaN      104.0   \n",
       "4  Rashard Anderson   CB  74  206   4.55      34.0        NaN      123.0   \n",
       "\n",
       "   Cone  Shuttle  Year    Pfr_ID    AV                Team  Round   Pick  \n",
       "0   NaN      NaN  2000  AbraJo00  26.0       New York Jets    1.0   13.0  \n",
       "1   NaN      NaN  2000  AlexSh00  26.0    Seattle Seahawks    1.0   19.0  \n",
       "2  8.48     4.98  2000  AlfoDa20   0.0  Kansas City Chiefs    6.0  188.0  \n",
       "3  7.29     4.49  2000       NaN   0.0                 NaN    NaN    NaN  \n",
       "4  7.18     4.15  2000  AndeRa21   6.0   Carolina Panthers    1.0   23.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data: modify path if data isn't in currend working directory\n",
    "data_df = pd.read_csv('combine_data_since_2000_PROCESSED_2018-04-26.csv')\n",
    "\n",
    "# make a subset of players that have been in the league for 3+ years, we will use this for our model\n",
    "data_df2 = data_df.loc[data_df.Year <= 2015].copy()\n",
    "data_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Forty</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>BenchReps</th>\n",
       "      <th>BroadJump</th>\n",
       "      <th>Cone</th>\n",
       "      <th>Shuttle</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pfr_ID</th>\n",
       "      <th>AV</th>\n",
       "      <th>Team</th>\n",
       "      <th>Round</th>\n",
       "      <th>Pick</th>\n",
       "      <th>AV_pctile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Abraham</td>\n",
       "      <td>OLB</td>\n",
       "      <td>76</td>\n",
       "      <td>252</td>\n",
       "      <td>4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>AbraJo00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>New York Jets</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.951482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shaun Alexander</td>\n",
       "      <td>RB</td>\n",
       "      <td>72</td>\n",
       "      <td>218</td>\n",
       "      <td>4.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>AlexSh00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.936123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darnell Alford</td>\n",
       "      <td>OT</td>\n",
       "      <td>76</td>\n",
       "      <td>334</td>\n",
       "      <td>5.56</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.48</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2000</td>\n",
       "      <td>AlfoDa20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kyle Allamon</td>\n",
       "      <td>TE</td>\n",
       "      <td>74</td>\n",
       "      <td>253</td>\n",
       "      <td>4.97</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.29</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashard Anderson</td>\n",
       "      <td>CB</td>\n",
       "      <td>74</td>\n",
       "      <td>206</td>\n",
       "      <td>4.55</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2000</td>\n",
       "      <td>AndeRa21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.630058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Pos  Ht   Wt  Forty  Vertical  BenchReps  BroadJump  \\\n",
       "0      John Abraham  OLB  76  252   4.55       NaN        NaN        NaN   \n",
       "1   Shaun Alexander   RB  72  218   4.58       NaN        NaN        NaN   \n",
       "2    Darnell Alford   OT  76  334   5.56      25.0       23.0       94.0   \n",
       "3      Kyle Allamon   TE  74  253   4.97      29.0        NaN      104.0   \n",
       "4  Rashard Anderson   CB  74  206   4.55      34.0        NaN      123.0   \n",
       "\n",
       "   Cone  Shuttle  Year    Pfr_ID    AV                Team  Round   Pick  \\\n",
       "0   NaN      NaN  2000  AbraJo00  26.0       New York Jets    1.0   13.0   \n",
       "1   NaN      NaN  2000  AlexSh00  26.0    Seattle Seahawks    1.0   19.0   \n",
       "2  8.48     4.98  2000  AlfoDa20   0.0  Kansas City Chiefs    6.0  188.0   \n",
       "3  7.29     4.49  2000       NaN   0.0                 NaN    NaN    NaN   \n",
       "4  7.18     4.15  2000  AndeRa21   6.0   Carolina Panthers    1.0   23.0   \n",
       "\n",
       "   AV_pctile  \n",
       "0   0.951482  \n",
       "1   0.936123  \n",
       "2   0.002611  \n",
       "3   0.003509  \n",
       "4   0.630058  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the player AV percentiles by position\n",
    "data_df2['AV_pctile'] = (data_df2.groupby('Pos').AV.rank(pct=True,\n",
    "                                                         method='min', \n",
    "                                                         ascending=True))\n",
    "data_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Forty</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>BenchReps</th>\n",
       "      <th>BroadJump</th>\n",
       "      <th>Cone</th>\n",
       "      <th>Shuttle</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pfr_ID</th>\n",
       "      <th>AV</th>\n",
       "      <th>Team</th>\n",
       "      <th>Round</th>\n",
       "      <th>Pick</th>\n",
       "      <th>AV_pctile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Boireau</td>\n",
       "      <td>DE</td>\n",
       "      <td>76</td>\n",
       "      <td>274</td>\n",
       "      <td>5.09</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>7.68</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Courtney Brown</td>\n",
       "      <td>DE</td>\n",
       "      <td>77</td>\n",
       "      <td>269</td>\n",
       "      <td>4.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>BrowCo22</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Cleveland Browns</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamont Bryant</td>\n",
       "      <td>DE</td>\n",
       "      <td>75</td>\n",
       "      <td>260</td>\n",
       "      <td>4.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>BryaLa00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonardo Carson</td>\n",
       "      <td>DE</td>\n",
       "      <td>73</td>\n",
       "      <td>283</td>\n",
       "      <td>5.06</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7.82</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2000</td>\n",
       "      <td>CarsLe20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>San Diego Chargers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.730583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rameel Connor</td>\n",
       "      <td>DE</td>\n",
       "      <td>75</td>\n",
       "      <td>276</td>\n",
       "      <td>5.00</td>\n",
       "      <td>35.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player Pos  Ht   Wt  Forty  Vertical  BenchReps  BroadJump  Cone  \\\n",
       "0  Michael Boireau  DE  76  274   5.09      29.0       26.0      105.0  7.68   \n",
       "1   Courtney Brown  DE  77  269   4.78       NaN        NaN        NaN   NaN   \n",
       "2    Lamont Bryant  DE  75  260   4.91       NaN       17.0        NaN   NaN   \n",
       "3  Leonardo Carson  DE  73  283   5.06      28.0       22.0      106.0  7.82   \n",
       "4    Rameel Connor  DE  75  276   5.00      35.5       25.0      121.0  7.65   \n",
       "\n",
       "   Shuttle  Year    Pfr_ID    AV                Team  Round   Pick  AV_pctile  \n",
       "0     4.49  2000       NaN   0.0                 NaN    NaN    NaN   0.002427  \n",
       "1      NaN  2000  BrowCo22  16.0    Cleveland Browns    1.0    1.0   0.871359  \n",
       "2      NaN  2000  BryaLa00   0.0                 NaN    NaN    NaN   0.002427  \n",
       "3     4.75  2000  CarsLe20  10.0  San Diego Chargers    4.0  113.0   0.730583  \n",
       "4     4.45  2000       NaN   0.0                 NaN    NaN    NaN   0.002427  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data for the football position we want, in this case it's DE \n",
    "pos_df = data_df2.loc[data_df2.Pos=='DE'].copy().reset_index(drop=True)\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Split testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_df = pos_df.loc[pos_df.Year <= 2011]\n",
    "test_df  = pos_df.loc[pos_df.Year.isin([2012, 2013, 2014, 2015])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of feature names\n",
    "features = ['Forty', 'Wt', 'Ht', 'Vertical', 'BenchReps', 'BroadJump', 'Cone', 'Shuttle']\n",
    "# define what we want to predict (label)\n",
    "target   = 'AV_pctile'\n",
    "\n",
    "# separate feature (X) and label (y) values from training set\n",
    "X = train_df[features].values\n",
    "y = train_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature values: [[  5.09 274.    76.    29.    26.   105.     7.68   4.49]\n",
      " [  4.78 269.    77.      nan    nan    nan    nan    nan]\n",
      " [  4.91 260.    75.      nan  17.      nan    nan    nan]\n",
      " [  5.06 283.    73.    28.    22.   106.     7.82   4.75]\n",
      " [  5.   276.    75.    35.5   25.   121.     7.65   4.45]]\n",
      "Label values: [0.00242718 0.87135922 0.00242718 0.73058252 0.00242718]\n"
     ]
    }
   ],
   "source": [
    "# What do X and y look like?\n",
    "print(\"Feature values: {}\".format(X[:5,:])) # this is a numpy array\n",
    "print(\"Label values: {}\".format(y[:5])) # this is a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "In this tutorial we're going to use scikit-learn's `Pipeline` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` is a method that combines a customizable number of steps in a machine learning pipeline into one. [This paper](https://arxiv.org/pdf/1309.0238.pdf) on scikit-learn's API has a good explanation of what `Pipeline` is, on page 8-9. A brief explanation with definitions (quotes are from the API paper):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Definitions:* <br>\n",
    "An **estimator** has a fuzzy definition; in scikit-learn it encompasses both transformers and predictors. <br>\n",
    "A **predictor** is anything that makes predictions; like our Random Forest model.<br>\n",
    "A **transformer** is anything that transforms data; for example, OneHot Encoder. (Note: This is *not* the NLP deep learning method Transformer that works on sequence transduction. See post [here](https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65))<br>\n",
    "An **imputer** infers missing values from the data. in scikit-learn, this is considered a subset of transformer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explanation:*<br>\n",
    "`Pipeline` chains multiple estimators (transformers and predictors) together. \"A sequence of N such\n",
    "steps can be combined into a Pipeline if the first N − 1 steps are transformers;\n",
    "the last can be either a predictor, a transformer or both.\"<br>\n",
    "In other words, `Pipeline` is used to combine multiple steps in a machine learning pipeline into one, and this does not have to include the model itself; it can be used to pre-process data. The `Pipeline` acts as whatever its last step is. \"The pipeline exposes all the\n",
    "methods the last estimator in the pipe exposes. That is, if the last estimator is\n",
    "a predictor, the pipeline can itself be used as a predictor. If the last estimator is\n",
    "a transformer, then the pipeline is itself a transformer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're using the `Pipeline` object to encompass our imputer (used to impute the nan's we saw in the training data) and our predictor (the Random Forest Regression model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our pipeline for this model\n",
    "\n",
    "# Since we're using RF, need to define our random state\n",
    "# the RANDOM_STATE parameter for RF models is (from the scikit-optimize docs):\n",
    "# Pseudo random number generator state used for random uniform sampling from lists\n",
    "# of possible values instead of scipy.stats distributions\n",
    "RANDOM_STATE = 420 \n",
    "pipe = Pipeline([(\"imputer\", SimpleImputer()), \n",
    "                 (\"estimator\", RandomForestRegressor(random_state=RANDOM_STATE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tune model parameters and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **parameters** of a machine learning model are internal to the model, and optimal values are learned during the training process. However, machine learning models also have **hyperparameters**, or, parameters that are important to the model's performance, but can't be learned from the data (for example, how many trees should be in our random forest?). In order to choose the optimal hyperparameters, we can perform one of several methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**: Test every possible combination of hyperparameters. This is very intensive for most models.<br>\n",
    "**Random Search**: Randomly choose hyperparameters from a distribution. Has better and faster performance than Grid Search. Explanation of why random search is better can be found [here](https://medium.com/rants-on-machine-learning/smarter-parameter-sweeps-or-why-grid-search-is-plain-stupid-c17d97a0e881)<br>\n",
    "**Bayes Search**: Uses Bayesian optimization to search for hyperparameters. Better and faster than both the above methods. A detailed explanation can be found [here](https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll use the `BayesSearchCV` method from scikit-optimize (Docs [here](https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV\n",
    "))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define the parameter space over which to search \n",
    "rf_param_space = {\n",
    "    'imputer__strategy': Categorical(['mean', 'median', 'most_frequent']),\n",
    "    'estimator__max_features': Integer(1, 8),\n",
    "    'estimator__n_estimators': Integer(50, 500), \n",
    "    'estimator__min_samples_split': Integer(2, 200),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we define a scoring function that will be used to evaluate the performance of the model with \n",
    "# various hyperparameters. r2 is Pearson's correlation coefficient.\n",
    "from sklearn.metrics import r2_score  \n",
    "r2 = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note about make_scorer:\n",
    "From the docs:<br>\n",
    "You can generate even more flexible model scorers by constructing your own scoring object from scratch, without using the make_scorer factory. For a callable to be a scorer, it needs to meet the protocol specified by the following two rules:\n",
    "1. It can be called with parameters (estimator, X, y), where estimator is the model that should be evaluated, X is validation data, and y is the ground truth target for X (in the supervised case) or None (in the unsupervised case).\n",
    "2. It returns a floating point number that quantifies the estimator prediction quality on X, with reference to y. Again, by convention higher numbers are better, so if your scorer returns loss, that value should be negated.\n",
    "\n",
    "This is why, when we call r2 later on, we call it as: \n",
    "\n",
    "    r2(search, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our Bayes search object using the Sklearn-Optimize package\n",
    "\n",
    "N_JOBS=8\n",
    "\n",
    "search = BayesSearchCV(pipe,                      # Estimator\n",
    "                       rf_param_space,            # Search_space\n",
    "                       cv=10,                     # Cross-validation generator or an iterable\n",
    "                       n_jobs=N_JOBS,             # Number of job run in parallel \n",
    "                       verbose=0, \n",
    "                       error_score=-9999,         # Value to assign to the score if an error occurs in estimator fitting.\n",
    "                       scoring=r2,                # Loss function\n",
    "                       random_state=RANDOM_STATE, # For random uniform sampling\n",
    "                       return_train_score=True,   # The cv_results_ attribute will include training scores.\n",
    "                       n_iter=10)                 # Number of parameter settings that are sampled.\n",
    "\n",
    "# n_iter is set very low in order to run the whole thing faster, would nnormally use much higher number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the output of `BayesSearchCV( )`? i.e., what is in our object `search`? <br>\n",
    "\n",
    "*Attributes:* <br>\n",
    "**cv_results_**: dict of numpy (masked) ndarrays <br>\n",
    "A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame. <br>\n",
    "\n",
    "**best_estimator_**: estimator <br>\n",
    "Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False. <br>\n",
    "\n",
    "**best_score_** : float <br>\n",
    "Score of best_estimator_ on the left out data.<br>\n",
    "\n",
    "**best_params_**: dict <br>\n",
    "Parameter setting that gave the best results on the hold out data. <br>\n",
    "\n",
    "**best_index_**: int <br>\n",
    "The index (of the `cv_results_` arrays) which corresponds to the best candidate parameter setting. <br>\n",
    "\n",
    "The dict at `search.cv_results_['params'][search.best_index_]` gives the parameter setting for the best model, that gives the highest mean score (`search.best_score_`). <br>\n",
    "\n",
    "**scorer_**: function <br>\n",
    "Scorer function used on the held out data to choose the best parameters for the model. <br>\n",
    "\n",
    "**n_splits_**: int <br>\n",
    "The number of cross-validation splits (folds/iterations).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class methods used in this tutorial: \n",
    "1. `fit(self,X,y,groups,callback)` : Run fit on the estimator with randomly drawn parameters. Only X and y are required, can provide group labels used while splitting the dataset into train/test. \n",
    "2. `predict(self,X)` : Call predict on the estimator with the best found parameters --> predicts labels/values for the provided instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=10, error_score=-9999,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('imputer',\n",
       "                                         SimpleImputer(add_indicator=False,\n",
       "                                                       copy=True,\n",
       "                                                       fill_value=None,\n",
       "                                                       missing_values=nan,\n",
       "                                                       strategy='mean',\n",
       "                                                       verbose=0)),\n",
       "                                        ('estimator',\n",
       "                                         RandomForestRegressor(bootstrap=True,\n",
       "                                                               ccp_alpha=0.0,\n",
       "                                                               criterion='mse',\n",
       "                                                               max_depth=None,\n",
       "                                                               max_features='auto',\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               max_samples=None,\n",
       "                                                               min_...\n",
       "              search_spaces={'estimator__max_features': Integer(low=1, high=8, prior='uniform', transform='identity'),\n",
       "                             'estimator__min_samples_split': Integer(low=2, high=200, prior='uniform', transform='identity'),\n",
       "                             'estimator__n_estimators': Integer(low=50, high=500, prior='uniform', transform='identity'),\n",
       "                             'imputer__strategy': Categorical(categories=('mean', 'median', 'most_frequent'), prior=None)},\n",
       "              verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit (train) the model \n",
    "# need to train the model before any of the following steps can be performed\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('estimator__max_features', 6),\n",
       "             ('estimator__min_samples_split', 42),\n",
       "             ('estimator__n_estimators', 375),\n",
       "             ('imputer__strategy', 'most_frequent')])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view best model parameters \n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1251275916733097"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view score of best_estimator on the left out data (i.e. how did the model perform?)\n",
    "# this is the score using the performance metric (scorer) that we provided to BayesSearchCV( ), here is r2\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE TO SELF** need to figure out what the \"left out\" data is, is this the best score of the cross validation splits, when the model is applied to the 10% that was left out (but that the model has already seen)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimator__max_features</th>\n",
       "      <th>param_estimator__min_samples_split</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "      <th>param_imputer__strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.054400</td>\n",
       "      <td>0.102235</td>\n",
       "      <td>0.101677</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>0.054914</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.135804</td>\n",
       "      <td>0.085493</td>\n",
       "      <td>0.092222</td>\n",
       "      <td>0.111375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.677079</td>\n",
       "      <td>0.581807</td>\n",
       "      <td>0.072173</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>5</td>\n",
       "      <td>142</td>\n",
       "      <td>287</td>\n",
       "      <td>median</td>\n",
       "      <td>{'estimator__max_features': 5, 'estimator__min...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.075334</td>\n",
       "      <td>0.181726</td>\n",
       "      <td>0.202825</td>\n",
       "      <td>0.058129</td>\n",
       "      <td>0.092091</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.134274</td>\n",
       "      <td>0.144350</td>\n",
       "      <td>0.158326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683111</td>\n",
       "      <td>0.198726</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>137</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'estimator__max_features': 7, 'estimator__min...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.059033</td>\n",
       "      <td>0.124095</td>\n",
       "      <td>0.165521</td>\n",
       "      <td>0.064966</td>\n",
       "      <td>0.095709</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>0.130411</td>\n",
       "      <td>0.130675</td>\n",
       "      <td>0.116789</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371853</td>\n",
       "      <td>0.419917</td>\n",
       "      <td>0.067260</td>\n",
       "      <td>0.022366</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "      <td>231</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>{'estimator__max_features': 7, 'estimator__min...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.060937</td>\n",
       "      <td>0.233634</td>\n",
       "      <td>0.284892</td>\n",
       "      <td>0.048825</td>\n",
       "      <td>0.094346</td>\n",
       "      <td>-0.006292</td>\n",
       "      <td>0.241879</td>\n",
       "      <td>0.111467</td>\n",
       "      <td>0.132016</td>\n",
       "      <td>0.176489</td>\n",
       "      <td>...</td>\n",
       "      <td>2.690099</td>\n",
       "      <td>0.545921</td>\n",
       "      <td>0.181167</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>375</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>{'estimator__max_features': 6, 'estimator__min...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.057614</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.130069</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.067302</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.151105</td>\n",
       "      <td>0.092738</td>\n",
       "      <td>0.092853</td>\n",
       "      <td>0.114085</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256543</td>\n",
       "      <td>0.291273</td>\n",
       "      <td>0.063102</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "      <td>217</td>\n",
       "      <td>median</td>\n",
       "      <td>{'estimator__max_features': 5, 'estimator__min...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -0.054400           0.102235           0.101677           0.034888   \n",
       "1          -0.075334           0.181726           0.202825           0.058129   \n",
       "2          -0.059033           0.124095           0.165521           0.064966   \n",
       "3          -0.060937           0.233634           0.284892           0.048825   \n",
       "4          -0.057614           0.110046           0.130069           0.048667   \n",
       "\n",
       "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0           0.054914           0.031297           0.135804           0.085493   \n",
       "1           0.092091           0.000007           0.195300           0.134274   \n",
       "2           0.095709          -0.004723           0.130411           0.130675   \n",
       "3           0.094346          -0.006292           0.241879           0.111467   \n",
       "4           0.067302           0.022258           0.151105           0.092738   \n",
       "\n",
       "   split8_test_score  split9_test_score  ...  mean_fit_time  std_fit_time  \\\n",
       "0           0.092222           0.111375  ...       1.677079      0.581807   \n",
       "1           0.144350           0.158326  ...       0.683111      0.198726   \n",
       "2           0.116789           0.122949  ...       1.371853      0.419917   \n",
       "3           0.132016           0.176489  ...       2.690099      0.545921   \n",
       "4           0.092853           0.114085  ...       1.256543      0.291273   \n",
       "\n",
       "   mean_score_time  std_score_time  param_estimator__max_features  \\\n",
       "0         0.072173        0.025605                              5   \n",
       "1         0.032045        0.015707                              7   \n",
       "2         0.067260        0.022366                              7   \n",
       "3         0.181167        0.109400                              6   \n",
       "4         0.063102        0.022147                              5   \n",
       "\n",
       "   param_estimator__min_samples_split  param_estimator__n_estimators  \\\n",
       "0                                 142                            287   \n",
       "1                                  93                            137   \n",
       "2                                 117                            231   \n",
       "3                                  42                            375   \n",
       "4                                 132                            217   \n",
       "\n",
       "   param_imputer__strategy                                             params  \\\n",
       "0                   median  {'estimator__max_features': 5, 'estimator__min...   \n",
       "1                     mean  {'estimator__max_features': 7, 'estimator__min...   \n",
       "2            most_frequent  {'estimator__max_features': 7, 'estimator__min...   \n",
       "3            most_frequent  {'estimator__max_features': 6, 'estimator__min...   \n",
       "4                   median  {'estimator__max_features': 5, 'estimator__min...   \n",
       "\n",
       "   rank_train_score  \n",
       "0                 8  \n",
       "1                 5  \n",
       "2                 6  \n",
       "3                 1  \n",
       "4                 7  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View scores for training and testing of cross-validation splits \n",
    "searchResults = pd.DataFrame(search.cv_results_)\n",
    "searchResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.031092927334830156"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now apply the model to the test data\n",
    "\n",
    "# define test set data\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df[target].values\n",
    "\n",
    "# apply the model\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "# evaluate performance on test data\n",
    "model_test_score = r2(search, X_test, y_test) \n",
    "model_test_score # why is this negative? Does this mean the model is really bad? Why is it so much worse on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23099783203501978, 0.02355094844797427)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the correlation between ground truth and predicted values with pearson correlation coefficient (PCC)\n",
    "from scipy.stats import pearsonr\n",
    "pearsonr(y_test, y_pred) # returns (r, two-tailed p-value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE TO SELF**: why is this such a better score than r2? Shouldn't r2 be the same exact thing??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Learn About Feature Importance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn about: <br>\n",
    "A. Gini impurity, and its regression counterpart <br>\n",
    "B. Mean Decrease Impurity, and how it's calculated using A. <br>\n",
    "C. Mean Decrease Accuracy, also known as Permutation Importance \n",
    "D. Pros and cons of each method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Gini Impurity and Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini Impurity\n",
    "Gini impurity is a measure of how good a given split is in a classification tree. First, let's review how classification trees work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the whole dataset. Each *instance* has some data associated with it; these data fall into groups called *features*. Each instance also has a *label* associated with it; this label represents the group to whcih the instance belongs. A classification tree aims to split the data in such a way that at the end, we have a separate group for each type of label. This splitting is done by using the information we have about each instance: the features. Consider the following example:\n",
    "\n",
    "![title](img/Classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original dataset is hours of the day, during one week. The features associated with each hour are, Out Of Food?, Raining?, and Hungry?. By splitting the data based on what value they have for a certain feature, we can decide if an hour belongs to the category where we should go to the store, or not go to the store. The same logic applies if we're trying to classify things into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does Gini impurity have to do with all this? Well, imagine that we're training a model to classify things using a decision tree. We could use different features at different nodes (these are called splits), and it would give us vastly different outcomes. Some versions of the tree are clearly better than others, because depending on which features we put where, we might mis-classify many instances. But what if we have lots of features, and it isn't intuitive which set of splits is better than another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following figure, let's walk through a simple explanation of Gini impurity, adapted from [this post](https://victorzhou.com/blog/gini-impurity/).\n",
    "\n",
    "![title](img/Gini.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini impurity is calculated for each split (also called a node). Imagine we want to calculate the Gini impurity of node $n_{j}$. The dots around each node represent the data points (instances) that have arrived to that node by following the previous splits in the tree. Here, purple and red represent the two different classes we're trying to classify. Our simple explanation is the following: for each split,\n",
    "\n",
    "1. Randomly pick a point within the split \n",
    "2. Randomly classify it according to the class distribution within that split (e.g. if there are 10 points, 5 from Class A and 5 from Class B, half the time we’d classify it as A, the other half B)\n",
    "3. Determine the probability that we classify the datapoint incorrectly. This is the Gini Impurity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is summarized in the following table for our example. First, we determine the probability each even occuring: choosing a point of that color (Step 1), and then classifying it correctly or incorrectly (Step 2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Event | Classification| Math| Probability   |\n",
    "|:------:|:------:|:------:|:-----:|\n",
    "| Pick red, classify red | Correct|  $\\frac{5}{7}$ \\* $\\frac{5}{7}$| 0.51|\n",
    "| Pick red, classify purple | Incorrect| $\\frac{5}{7}$ \\* $\\frac{2}{7}$| 0.20 |\n",
    "| Pick purple, classify purple | Correct| $\\frac{2}{7}$ \\* $\\frac{2}{7}$| 0.08 |\n",
    "| Pick purple, classify red | Incorrect | $\\frac{2}{7}$ \\* $\\frac{5}{7}$| 0.20 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take the event probabilities for the incorrect classifications and add them together to get the Gini impurity (Step 3). \n",
    "\n",
    "$$\\textrm{Gini impurity for } n_{j} = 0.20+0.20=0.40$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was possible for a simple example, but what about more complicated ones? Now let's talk about the mathematical definition of Gini impurity. <br>\n",
    "\n",
    "**Definition**: $$\\sum\\limits_{i=1}^C p(i)(1-p(i))$$\n",
    "\n",
    "where $p(i)$ is the probability of picking a datapoint with class $i$, and $C$ is the total number of classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use our example above with this formula: \n",
    "\n",
    "$$p(red)(1-p(red)) + p(purple)(1-p(purple))$$\n",
    "$$\\frac{5}{7}(1-\\frac{5}{7})) + \\frac{2}{7}(1-\\frac{2}{7}))$$\n",
    "$$0.20+0.20$$\n",
    "$$0.40$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get the same result with this formula!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, what is Gini impurity? It's the probability of classifying something incorrectly at a given node. So the lower the impurity, the better we are at making predictions at that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impurity for regressions\n",
    "As you can see, this method only works if we are working with a classification problem. What about regressions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's review how regression trees work. This section is adapted from [this absolutely wonderful lecture](http://www.stat.cmu.edu/~cshalizi/350-2006/lecture-10.pdf). <br>\n",
    "\n",
    "In a linear regression, we fit one model (predictive formula) over the entire data-space. However, if the data has lots of features which interact in complicated, nonlinear ways, it’s very difficult to fit a good linear model, and because of all the terms you would have to add to the equation in order to get a fit over the whole data space, the resulting model is extraordinarily complicated and uninterpretable. <br>\n",
    "\n",
    "Therefore, we can do something called recursive partitioning. Instead of fitting a global model, we can subdivide, or partition, the dataspace into smaller regions. We continue splitting these partitions (which is why it’s called recursive partitioning) until we have manageable chunks of data-space where we can fit simple models. The division of the dataspace is done by features, the same as for a classification tree. <br>\n",
    "\n",
    "Regression trees are a way of representing recursive partitioning. Each of the terminal leaves of the tree represents a final partition, which has attached to it a simple model, as illustrated below. <br>\n",
    "\n",
    "![title](img/regression.png)\n",
    "\n",
    "In the above, the word at each node is the feature on which the data is being split. These are continuous features, and the partition is made by choosing a value of that feature at which to split the data. As you can see, Horsepower shows up three times, and each time, a different value is used to make the split.You can get a more intuitive sense of this by looking at the following figure: <br>\n",
    "\n",
    "![title](img/Partitions.png)\n",
    "\n",
    "When there are more than two features, we are looking for partitions ina higher dimensional space. <br>\n",
    "\n",
    "What are the simple local models? In a classic regression tree, this is just the sample mean of the dependent variable (from the training data) within the given partition. In the decision tree this is represented as \"Price = (some number)\", and in the partition figure, it is the number in red within each partition. This means a classic regression tree is a piecewise-constant model. Since this is easy to calculate once a tree is decided upon, all effort should go into finding the best set of partitions. <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're familiar with how splits are made in a regression tree, let's talk about the regression version of Gini impurity. It's actually much simpler: it's just Mean Square Error (MSE). This explanation is adapted from [this post](https://towardsdatascience.com/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3) on how feature importances are implemented in scikit-learn. <br>\n",
    "\n",
    "**Definition**:\n",
    "\n",
    "$$\\frac{1}{N} \\sum\\limits_{i=1}^N (y_{i} - \\mu)^2$$\n",
    "\n",
    "Where $y_{i}$ is the label for an instance (its value), $N$ is the number of instances and $\\mu$ is the mean given by $\\frac{1}{N} \\sum\\limits_{i=1}^N y_{i}$. In plain english, MSE is the mean of the squared differences (error) between the true value (instance label) and the group mean at the node ($\\mu$), for all instances at the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work through a simple example, using the following tree: \n",
    "\n",
    "![title](img/MSE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the MSE of $n_{j}$, we first have to calculate $\\mu$ at $n_{j}$. \n",
    "\n",
    "$$\\mu = \\frac{1+3+4+5+8+9}{6} = 5$$\n",
    "\n",
    "Then, we follow the formula:\n",
    "\n",
    "$$\\frac{1}{6}*((1-5)^2 + (3-5)^2 + (4-5)^2 + (5-5)^2 + (8-5)^2 + (9-5)^2) = 7.67$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does MSE mean intuitively, after we've worked through the above example? We could say that, at the end of a regression tree, predictions are made using the mean of all instances at the node. Therefore, the difference between a given instance label and the mean at the node is the error, because that’s how far off the prediction for that instance could be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Mean Decrease Impurity\n",
    "We can calculate impurity at nodes now, but so what? How can we use this to evalulate how good our tree is (and later on, our Random Forest model) at classification or regression? We can use Gini impurity and MSE to define something called Mean Decrease Impurity (MDI), which tells us how good a given feature is at helping to classify the data. MDI follows the same procedure for both classification and regression, and just uses different impurity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithm\n",
    "\n",
    "A short description of how this is implemented in scikit-learn (from the same source above):<br>\n",
    "“Feature importance is calculated as the decrease in node impurity weighted by the probability of reaching that node. The node probability can be calculated by the number of samples that reach the node, divided by the total number of samples. The higher the value the more important the feature.”  <br>\n",
    "\n",
    "What on earth does that mean? Let's break it down into steps. <br>\n",
    "\n",
    "**1. Calculate the importance of each node.**\n",
    "\n",
    "In order to do this, we use the following equation: \n",
    "\n",
    "$$ni_{j} = w_{j} C_{j} -  w_{left(j)} C_{left(j)} -  w_{right(j)} C_{right(j)}$$\n",
    "\n",
    "where <br>\n",
    "$ni_{j}$ = the importance of node $j$ <br>\n",
    "$w_{j}$ = weighted number of samples reaching node $j$ <br>\n",
    "$C_{j}$ = the impurity value of node $j$ (either Gini impurity or MSE) <br>\n",
    "$left(j)$ = child node from the left of the split made at node $j$ <br>\n",
    "$right(j)$ = child node from the right of the split made at node $j$ <br>\n",
    "\n",
    "In plain english: Node importance = (number of samples that reach this node ÷ total number of samples)\\*(Gini impurity of this node) - (number of samples that reach the left child of this node ÷ total number of samples)\\*(Gini impurity of the left child of this node) - (number of samples that reach the right child of this node ÷ total number of samples)\\*(Gini impurity of the right child of this node) <br>\n",
    "\n",
    "**2. Calculate the feature importance within this individual tree.**\n",
    "\n",
    "In order to do this, we use the following:\n",
    "\n",
    "$$fi_{i} = \\frac{\\sum\\limits_{j:\\textrm{node }j \\textrm{ splits on feature }i} ni_{j}}{\\sum\\limits_{k \\in all nodes} ni_{k}}$$\n",
    "\n",
    "where <br>\n",
    "$fi_{i}$ = the importance of feature $i$ <br>\n",
    "\n",
    "In plain english: Feature importance = (the sum of node importances for nodes that split on this feature) ÷ (sum of all node importances) \n",
    "\n",
    "**3. Normalize feature importance.**\n",
    "\n",
    "We normalize feature importances to a value between 0 and 1 by dividing by the sum of all feature importances.\n",
    "\n",
    "**4. Average feature importance across all trees.**\n",
    "\n",
    "Since a Random Forest is made up of many individual decision trees, we get overall feature importance by taking the sum of the importances for that feature, divided by the number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML_interpretability]",
   "language": "python",
   "name": "conda-env-ML_interpretability-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
